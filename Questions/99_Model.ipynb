{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Diagnosing Model Performance with Learning Curves\n",
    "\n",
    "Check PDF 1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parametric models\n",
    "Parametric models assume that the data follows a specific probability distribution, such as normal, binomial, or exponential. They also have a fixed number of parameters that describe the shape and location of the distribution, such as mean, variance, or rate. Parametric models are easier to fit, interpret, and generalize than non-parametric models, as they require less data and computation. However, they can be biased and inaccurate if the data does not match the assumed distribution, or if there are outliers or non-linear relationship\n",
    "linear regression, logistic regression\n",
    "\n",
    "Non-parametric models\n",
    "Non-parametric models do not make any assumptions about the distribution of the data. They are more flexible and adaptable than parametric models, as they can capture complex and irregular patterns that parametric models cannot. They also do not depend on the choice of parameters, as they use the data itself to determine the shape and form of the model. However, non-parametric models are more difficult to fit, interpret, and generalize than parametric models, as they require more data and computation. They can also be noisy and overfit the data, especially if there are irrelevant or redundant variables.\n",
    "k-nearest neighbors, decision trees,svm\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
